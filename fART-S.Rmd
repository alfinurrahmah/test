---
title: "fART-S"
author: "AlfiNurrahmah"
date: "3/13/2022"
output: html_document
---
##List Parameter Fuzzy ART

choiceFunction
vigilance (rho)
choiceParam (alpha)
learningParam (beta) 
input
selectedCategory
currentInput
categoryWeight === w
kelasCategory 
indexKelasCategory

## Parameter kmeans
k #jumlah cluster yang akan dibentuk 
jenis ukuran jarak


##List Function
art <- function(inputNode, categoryNode, choiceParam, learningParam, vigilance){}

setCurrentInput <- function(InputData){}

fuzzyNorm <- function(input){} == sum

fuzzyAnd <- function(inputA, inputB){}

setChoiceFunction <- function(){}

chooseCategory <- function(){} #pilihCategory

vigilanceCheck <- function(){}

learn <- function(){}

addCategory <- function(){}

processCurrentInput <- function(){}

TFormFuzzyArt.operate <- function(){}

## INISIASI
# ```{r}
# inputData = NA
# n <- dim(inputData)[1] #num_clusters
# k <- dim(inputData)[2] #num_category
# ```


## fungsi scaledData 
# ```{r}
# scaledData <- function(inputData){
#   s_min <- 0
#   s_max <- 0
#   list <- as.matrix(inputData)
#   for (i in 1:n){
#     for (j in 1:k){
#       if (s_min = 0 || s_min > list[i,j]){
#       s_min <- list[i,j]
#       } 
#       if (s_max){
#       s_max <- list[i,j]
#       }
#     }
#   }
#   for (i in 1:n){
#     for (j in 1:k){
#       list[i,j] = (list[i,j] - s_min)/(s_max - s_min)
#     }
#   }
#   return(list)
# }
# ```

## Fungsi untuk menormalisasi data
```{r}
normalize_data <- function(input)
{
  normalized <- apply(X = input,MARGIN = 2,FUN = function(col){(col-min(col))/(max(col)-min(col))})
  return(normalized)
}
```

```{r}
notnum <- c("a","b")
input = notnum
if (is.numeric(input))
    {
    # normalize data input
    normalized_data <- normalize_data(input)
    } else {stop(paste("Input data is not numeric"))}
    
```



## fungsi complementCodedConversion
```{r}
complement_coded_conv <- function(normalized_data)
{
  dataset <- cbind(normalized_data,1-normalized_data)
  return(dataset)
}
```



## fungsi fuzzy And
```{r}
fuzzy_and <- function(inputA, inputB)
{
  comb <- cbind(inputA,inputB)
  return(apply(X = comb,FUN = min,MARGIN = 1))
}
```

## fungsi fuzzy Norm
```{r}
fuzzy_norm <- function(input)
{
  return(sum(abs(input)))
}
```
## fungsi max fuzzy norm
```{r}
max_norm <- function(input)
{
  return(max(abs(input)))
}
```

## fungsi choice Tj
```{r}
choice_function <- function(input, category_w, alpha){
  Tj <- fuzzy_norm(fuzzy_and(input, category_w))/(alpha+fuzzy_norm(category_w))
  return(Tj)
}
```

## fungsi match Sj
```{r}
match_function <- function(input, category_w){
  Sj <- fuzzy_norm(fuzzy_and(input,category_w))/fuzzy_norm(input)
  return(Sj)
}
```
## fungsi vigilance check
```{r}
vigilance_check <- function(input, category_w, rho){
  vcheck <- match_function(input,category_w) >= rho
  return(vcheck)
}
```

## fungsi update weight
```{r}
update_weight <- function(input, category_w, beta){
  w_new <- beta*fuzzy_and(input,category_w) + (1-beta)*category_w
  return(w_new)
}
```



## fungsi untuk mencari Tj winner dan lolos vigilance check
```{r}
category_winner <- function(input, w, alpha, rho)
  {
    #w
    m = dim(w)[1] # number of clusters
    matches = rep(0,m)
    # matches = apply(X = w,MARGIN = 1, FUN = function(weight){return(choice_function(input, weight, alpha))})
    for (j in 1:m) {
      matches[j] = choice_function(input, w[j,], alpha)
    }
    
    match_iterations = 0
    while (match_iterations<length(matches)) 
    {
      # select the winning category uses which.max
      winner = which.max(matches) #location of the first max value
      if(vigilance_check(input,w[winner,],rho))
      {
        # induce resonance
        return(winner)
      } else 
      {
        # failed to match, try another Tj
        matches[winner] <- 0 # RESET
        match_iterations <- match_iterations+1
      }
    } 
    return(length(matches)+1)
  }
```


## fungsi learning 
```{r}
learn_pattern <- function(input, w, rho, alpha, beta, num_clusters, max_clusters, 
                            output.learn = list(w = NA, num_clusters = NA, winner = NA))
  {
    # found the location of winning category 
    winner <- category_winner(input = input, w = w, alpha = alpha, rho = rho)
    
    if(winner > num_clusters)
    {
      # create a new category
      num_clusters <- num_clusters + 1
      
      # was it reached the maximum cluster count?
      if(num_clusters > max_clusters) stop("Error. The maximum cluster count has been reached!")
      
      w = rbind(w,input)
    }
    
    # update the old weight 
    w[winner,] <- update_weight(input, w[winner,], beta)
    
    output.learn$winner = winner
    output.learn$w = w
    output.learn$num_clusters = num_clusters
    return(output.learn)
  }
```

```{r}
fuzzyart_training <- function(input, rho, alpha, beta, w_init = NA, max_clusters = 1000, max_epochs = 1000, eps = 10^-6)
    {
    
      start_time = Sys.time()
      ## save parameters
      params = list()
      params[["rho"]]         = rho
      params[["alpha"]]       = alpha
      params[["beta"]]        = beta
      params[["max_epochs"]]  = max_epochs
      params[["w_init"]]      = w_init
      
      # check parameter
      if(is.data.frame(input)){(input=as.matrix(input))}
      if (is.numeric(input))
      {
      # normalize data input
      normalized_data <- normalize_data(input)
      } else {stop("Error: Input data is not numeric")}
      
      
      # complement code conversion
      dataset <- complement_coded_conv(normalized_data)
      
      # determine the size of features/variables data
      num_features <- ncol(input)
      
      # init weight
      #w_init = NA
      if(is.na(w_init))
      {
      w <- matrix(rep(1,num_features*2),nrow = 1)
      } else if (dim(w_init)[2]==num_features*2)
      {
        w <- w_init
      } else {stop("Error: Initial weight dimension is not the same as 2*num of features")}
      
      num_clusters <- dim(w)[1]
      
      #init variables
      max_clusters = max_clusters
      num_clusters_old = num_clusters
      cluster_labels = matrix(rep(NA, dim(dataset)[1]))
      iterations = 0
      w_old = w+1
      train_output_fa = list(w = NA, num_clusters = NA, winner = NA)
      index = 1:dim(dataset)[1]
      
      while (((sum(w_old-w)^2)>eps^2) & (iterations < max_epochs)) 
      {
      
        w_old = w
       
        for(i in index)
        {
          train_output_fa <- learn_pattern(dataset[i,], w, rho, alpha, beta, num_clusters, 
                                           max_clusters, output.learn =  train_output_fa)
          
          cluster_labels[i] <- train_output_fa$winner
          dimnames(cluster_labels)[1]<-dimnames(input)[1]
          w <- train_output_fa$w
          num_clusters <- train_output_fa$num_clusters
          
        }
        iterations = iterations+1
        
        if(num_clusters_old != num_clusters)
        {
          w_old = rbind(w_old,replicate(n = num_features*2, rep(1,num_clusters-num_clusters_old)))
          num_clusters_old = num_clusters
        }
      }
        
      fa_clusters = list(matrix(NA,nrow=num_clusters, ncol=num_features))
      size = matrix(NA,num_clusters)
      cent= matrix(NA,nrow=num_clusters,ncol=ncol(input))
      for(k in 1:num_clusters)
      {
        fa_clusters[[k]] <- matrix(input[which(cluster_labels == k),], ncol = num_features)
        dimnames(fa_clusters[[k]])[1]<-dimnames(input[which(cluster_labels == k),])[1]
        dimnames(fa_clusters[[k]])[2]<-dimnames(input)[2]
        if(is.null(nrow(fa_clusters[[k]])))
        {
          size[k] <- 0
        } else {size[k]<-nrow(fa_clusters[[k]])}
      }
      
      
      
      fa_centroids = matrix(NA,nrow=num_clusters,ncol=ncol(input))
      fa_centroids <- recalculate_centroids(fa_centroids,fa_clusters,num_clusters)
      dimnames(fa_centroids)[2]<-dimnames(input)[2]
      
      end_time <- Sys.time()
      running_time = end_time-start_time
      
      FuzzyArt_Out = list()
      FuzzyArt_Out[["labels"]] = cluster_labels
      FuzzyArt_Out[["size"]] = size
      FuzzyArt_Out[["clusters"]] = fa_clusters
      FuzzyArt_Out[["centroids"]] = fa_centroids
      FuzzyArt_Out[["weights"]] = w_old
      FuzzyArt_Out[["params"]] = params
      FuzzyArt_Out[["iterations"]] = iterations
      FuzzyArt_Out[["num_clusters"]] = num_clusters
      FuzzyArt_Out[["running_time"]]= running_time
      return(FuzzyArt_Out)
    }
```
```{r}
hm <- matrix(c(1,2,3,4,5,6,7,8,9,0), nrow=5)
rownames(hm)
```
```{r}
AKHIRNYA3  = fuzzyart_training(data100,alpha = .01,rho = .5,
                      beta = 1, max_epochs = 1000)
AKHIRNYA3
```

```{r}
AKHIRNYA4t <- fuzzyart_testing(data100, AKHIRNYA3)
AKHIRNYA4t
```
```{r}
AKHIRNYA4tkm<-kmeans_train(data100,k=AKHIRNYA4t$num_clusters,centroids = AKHIRNYA4t$centroids)
AKHIRNYA4tkm
```

```{r}
colnames(inputs)
colnames(datafix)
rownames(datafix)
head(datafix)
colnames(ikb20$centroids)<-colnames(datafix)
colnames(ikb20$clusters[[1]])<-colnames(datafix)
dimnames(ikb20$labels)[1]<-dimnames(datafix)[1]
str(ikb20$labels)
length(ikb20$labels)
```
```{r}
# train model IKB 20
ikb20  = fuzzyart_training(datafix[,2:5],alpha = .01,rho = .5,
                      beta = 1, max_epochs = 1000)
ikb20
#str(cbiris$weights)
```

```{r}
library(FuzzyART)
library(mclust)

# load data
inputs = subset(iris,select = -Species)
labels.true = as.numeric(unlist(iris$Species))
normalized_inputs = normalize(df = inputs)
# train model
cbiris  = fuzzyart_training(normalized_inputs,alpha = .01,rho = .4,
                      beta = 1, max_epochs = 1000)
cbiris
plot(inputs, col = cbiris$labels, pch = labels.true, 
     main = paste0("Dataset: Iris -- Rand Index: ", 
                   round(adjustedRandIndex(cbiris$labels,labels.true),digits = 2)))

```

```{r}
hiris <- cbind(cbiris$labels,labels.true)
hiris
```


```{r}
length(AKHIRNYA2$clusters[[5]])
is.null(AKHIRNYA2$clusters[[5]])
AKHIRNYA2$clusters[[2]]
str(AKHIRNYA2$clusters[[5]])
AKHIRNYA2$clusters[[2]][,2]
```


```{r}
tfa<-fuzzyart_training(book3, alpha = 0.3, rho = 0.5, beta = 0.08, max_epochs = 1000, max_clusters = 5)
tfa
```


```{r}
#fa_clusters = list(NA)
      size = matrix(NA,num_clusters)
      for(k in 1:num_clusters)
      {
        #fa_clusters[[k]] <- input[which(cluster_labels == k),]
        size[k]<-nrow(tfa$clusters[[k]])
      }
size      
length(tfa$clusters)
```



## fuzzyart_testing
```{r}
fuzzyart_testing <- function(input, FuzzyArt_Out)
    {
      start_time = Sys.time()
      if(is.null(FuzzyArt_Out)) stop("Error. Need to specify FuzzyArt_Out as a FuzzyART model as trained by FuzzyART_train")
      
      # check parameter
      if(is.data.frame(input)){(input=as.matrix(input))}
      if (is.numeric(input))
      {
      # normalize data input
      normalized_data <- normalize_data(input)
      } else {stop("Error: Input data is not numeric")}
      
      
      # complement code conversion
      dataset <- complement_coded_conv(normalized_data)
      num_clusters = FuzzyArt_Out$num_clusters
      
      cluster_labels = matrix(rep(NA, dim(dataset)[1]))
      cluster_labels = matrix(apply(dataset, MARGIN = 1,FUN = function(dataset){return(category_winner(input = dataset,w = FuzzyArt_Out$w,
                                                                                     alpha = FuzzyArt_Out$params$alpha, 
                                                                                     rho = FuzzyArt_Out$params$rho))}))
      num_clusters = FuzzyArt_Out$num_clusters
      dimnames(cluster_labels)[1]<-dimnames(input)[1]
      
      fa_clusters = list(matrix(NA,nrow=num_clusters, ncol=ncol(input)))
      size = matrix(NA,num_clusters)
      cent= matrix(NA,nrow=num_clusters,ncol=ncol(input))
      for(k in 1:num_clusters)
      {
        fa_clusters[[k]] <- matrix(input[which(cluster_labels == k),], ncol = ncol(input))
        dimnames(fa_clusters[[k]])[1]<-dimnames(input[which(cluster_labels == k),])[1]
        dimnames(fa_clusters[[k]])[2]<-dimnames(input)[2]
        if(is.null(nrow(fa_clusters[[k]])))
        {
          size[k] <- 0
        } else {size[k]<-nrow(fa_clusters[[k]])}
      }
      
      fa_centroids = matrix(NA,nrow=num_clusters,ncol=ncol(input))
      fa_centroids <- recalculate_centroids(fa_centroids,fa_clusters,num_clusters)
      dimnames(fa_centroids)[2]<-dimnames(input)[2]
      
      end_time <- Sys.time()
      running_time = end_time-start_time
      
      FuzzyArt_Res = list()
      FuzzyArt_Res[["labels"]] = cluster_labels
      FuzzyArt_Res[["size"]] = size
      FuzzyArt_Res[["clusters"]] = fa_clusters
      FuzzyArt_Res[["centroids"]] = fa_centroids
      FuzzyArt_Res[["weights"]] = FuzzyArt_Out$w
      FuzzyArt_Res[["params"]] = FuzzyArt_Out$params
      FuzzyArt_Res[["num_clusters"]] = num_clusters
      FuzzyArt_Res[["running_time"]]= running_time
      return(FuzzyArt_Res)
    }
```

```{r}
ttfa<-fuzzyart_testing(book3, tfa)
ttfa$labels
```
```{r}
kmttfa<-kmeans_train(book3, k = ttfa$num_clusters, centroids = ttfa$centroids, max_iter = 200, km_out = list(clusters=NA, centroids = NA,  labels=NA))
kmttfa
#cbkmeans2$labels
```

fuzzy art param
rho
alpha
beta
w_init = NA

k-means
jumlah cluster k = jumlah cluster dari fuzzy art 
centroid awal = centroid dari testing art

```{r}
fa_clusters = list()
  for(k in 1:num_clusters)
  {
    fa_clusters[[k]] <- dataset[which(cluster_labels == k),]
  }

  fa_centroids = list() 
  fa_centroids<-recalculate_centroids(centroids=fa_centroids, clusters=fa_clusters, k=num_clusters)
```


## fungsi menghitung linalg untuk euclidean distance
```{r}
linalg_norm <- function(inputA,inputB)
{
   return(sqrt(sum(abs(inputA-inputB)^2)))
}
#example
a <- c(-3,-2,-1,3,3,2,3)
b <- c(-3,-2,-1,0,1,2,3)
linalg_norm(a,b) #3.605
```
## fungsi menghitung euclidean distance
```{r}
# euc_dist <- function(input,centroids)
# {
#   ed=matrix(ncol=1)
#   #if (dim(inputA)[1]==0 | dim(inputB)[1]==0) return(Inf)
#   for (k in 1:dim(centroids)[1]) {
#     ed[k] <- linalg_norm(input,centroids[k,])
#   }
#   return(ed)
# }

```


## Fungsi assigning_cluster(input, centroids, k) dalam kmeans
```{r}
assigning_cluster <- function(input, centroids, k)
{
m = dim(input)[1]
  cluster_labels = matrix(NA,nrow=m)
nearest = NA
  for (j in 1:m) 
  {
    d = matrix(0,nrow=k)
    for (i in 1:k)
    {
      d[i] <- linalg_norm(input[j,],centroids[i,])
      
    }
    nearest = which.min(d)
    cluster_labels[j] = nearest
  }
return(cluster_labels)
}
```


## Fungsi recalculate_centroids untuk menghitung ulang centroid tiap cluster
```{r}
#fa_centroids = matrix(NA,nrow=k,ncol=ncol(input)+1)
  recalculate_centroids <- function(centroids, clusters, k)
  {
    for (i in 1:k)
    {
      centroids[i,] = apply(X=clusters[[i]], MARGIN=2, FUN = mean)
    }
    return(centroids)
  }
```

## kmeans_train 

```{r}
kmeans_train <- function(input, k, centroids = NULL, max_iter = 1000)
    {
      start_time = Sys.time()
      iterations = 0
      clust= list(matrix(NA,nrow=k, ncol=dim(input)[2]))
      labels=matrix(rep(NA, dim(input)[1]))
      size = matrix(NA,k)
      if(is.data.frame(input)){(input=as.matrix(input))}
      
      if(is.null(centroids))
      {
      centroids = matrix(NA,nrow=k,ncol=ncol(input))
        for (i in 1:k) {
          rand <- round(runif(1,1,nrow(input)),0)
          centroids[i,] =  rbind(input[rand,])
        } 
      } else {centroids=centroids}
      
      while(iterations <= max_iter)
      {
        centroids_old = centroids
        labels = assigning_cluster(input, centroids, k)
        for(i in 1:k)
        {
          clust[[i]] <- input[which(labels == i),]
          dimnames(clust[[i]])[1]<-dimnames(input[which(labels == i),])[1]
          dimnames(clust[[i]])[2]<-dimnames(input)[2]
          if(is.null(nrow(clust[[i]])))
          {
            size[i] <- 0
          } else {size[i]<-nrow(clust[[i]])}
        }
        centroids = recalculate_centroids(centroids_old, clust, k)
        if(all(centroids_old == centroids, na.rm = T)==TRUE)
        {
          break
        } else
        {
          iterations = iterations+1
        }
      }
      dimnames(labels)[1]<-dimnames(input)[1]
     
      
      end_time = Sys.time()
      running_time = end_time-start_time
      Kmeans_Res = list()
      Kmeans_Res$labels = labels
      Kmeans_Res$size = size
      Kmeans_Res$clusters = clust
      Kmeans_Res$centroids = centroids
      Kmeans_Res$running_time = running_time
      return(Kmeans_Res)
    }
```
```{r}
AKHIRNYATOT <- kmeans_train(data100, AKHIRNYA4t$num_clusters, AKHIRNYA4t$centroids)
AKHIRNYATOT
```


```{r}
cbkmeans3<-kmeans_train(book3, k = 4, centroids = NULL, max_iter = 200, km_out = list(clusters=NA, centroids = NA,  labels=NA))
cbkmeans3
#cbkmeans2$labels
```
```{r}
library(readxl)
ciris <- read_excel("C:/Users/ALFI/OneDrive/SKRIPSI/DATA/iris.xlsx", 
    sheet = "ciris")
ciris <- as.matrix(ciris)
cbkmiris <- kmeans_train(inputs, k = 3, centroids = NULL, max_iter = 200)
cbkmiris
cbfairis <- fuzzyart_training(inputs, alpha = .8,rho = .5,
                      beta = .12, max_epochs = 1000, max_clusters = 20)
cbfairis$labels
```
```{r}
library(caret)
confusionMatrix(table(as.factor(cbkmiris$labels),as.factor(labels.true)))
```

```{r}
library(stats)
pkgkmiris <- kmeans(inputs, 3, nstart = 25)
pkgkmiris
```

#==============

```{r}
ffakmct <- function(input, rho, alpha, beta, w_init = NA, 
                   max_epochs = 1000, max_clusters = 20, eps = 10^-6)
{
    start_time <- Sys.time()
    ## save parameters
    params = list()
    params[["rho"]]         = rho
    params[["alpha"]]       = alpha
    params[["beta"]]        = beta
    params[["max_epochs"]]  = max_epochs
    params[["w_init"]]      = w_init
    
    ## helpers function
    normalize_data <- function(input)
    {
      normalized <- apply(X = input,MARGIN = 2,FUN = function(col){(col-min(col))/(max(col)-min(col))})
      return(normalized)
    }
    
    complement_coded_conv <- function(normalized_data)
    {
      dataset <- cbind(normalized_data,1-normalized_data)
      return(dataset)
    }  
    
    fuzzy_and <- function(inputA, inputB)
    {
      comb <- cbind(inputA,inputB)
      return(apply(X = comb,FUN = min,MARGIN = 1))
    }
    
    fuzzy_norm <- function(input)
    {
      return(sum(abs(input)))
    }
    
    choice_function <- function(input, category_w, alpha)
    {
      Tj <- fuzzy_norm(fuzzy_and(input, category_w))/(alpha+fuzzy_norm(category_w))
      return(Tj)
    }
    
    match_function <- function(input, category_w)
    {
      Sj <- fuzzy_norm(fuzzy_and(input,category_w))/fuzzy_norm(input)
      return(Sj)
    }
    
    vigilance_check <- function(input, category_w, rho)
    {
      vcheck <- match_function(input,category_w) >= rho
      return(vcheck)
    }
    
    update_weight <- function(input, category_w, beta)
    {
      w_new <- beta*fuzzy_and(input,category_w) + (1-beta)*category_w
      return(w_new)
    }
    
    category_winner <- function(input, w, alpha, rho)
    {
      #w
      m = dim(w)[1] # number of clusters
      matches = rep(0,m)
      # matches = apply(X = w,MARGIN = 1, FUN = function(weight){return(choice_function(input, weight, alpha))})
      for (j in 1:m) {
        matches[j] = choice_function(input, w[j,], alpha)
      }
      
      match_iterations = 0
      while (match_iterations<length(matches)) 
      {
        # select the winning category uses which.max
        winner = which.max(matches) #location of the first max value
        if(vigilance_check(input,w[winner,],rho))
        {
          # induce resonance
          return(winner)
        } else 
        {
          # failed to match, try another Tj
          matches[winner] <- 0 # RESET
          match_iterations <- match_iterations+1
        }
      } 
      return(length(matches)+1)
    }
    
    learn_pattern <- function(input, w, rho, alpha, beta, num_clusters, max_clusters, 
                            output.learn = list(w = NA, num_clusters = NA, winner = NA))
    {
      # found the location of winning category 
      winner <- category_winner(input = input, w = w, alpha = alpha, rho = rho)
      
      if(winner > num_clusters)
      {
        # create a new category
        num_clusters <- num_clusters + 1
        
        # was it reached the maximum cluster count?
        if(num_clusters > max_clusters) stop("Error. The maximum cluster count has been reached!")
        
        w = rbind(w,input)
      }
      
      # update the old weight 
      w[winner,] <- update_weight(input, w[winner,], beta)
      
      output.learn$winner = winner
      output.learn$w = w
      output.learn$num_clusters = num_clusters
      return(output.learn)
    }
    
    
    linalg_norm <- function(inputA,inputB)
    {
      return(sqrt(sum(abs(inputA-inputB)^2)))
    }
    
    recalculate_centroids <- function(centroids, clusters, k)
    {
      for (i in 1:k)
      {
        centroids[i,] = apply(X=clusters[[i]], MARGIN=2, FUN = mean)
      }
      return(centroids)
    }


    assigning_cluster <- function(input, centroids, k)
    {
      m = dim(input)[1]
      cluster_labels = matrix(rep(NA, m))
      nearest = NA
      for (j in 1:m) 
      {
        d = matrix(0,nrow=k)
        for (i in 1:k)
        {
          d[i] <- linalg_norm(input[j,],centroids[i,])
          
        }
        nearest = which.min(d)
        cluster_labels[j] = nearest
      }
      return(cluster_labels)
    }
     
    ## Training Fuzzy ART neural network
    fuzzyart_training <- function(input, rho, alpha, beta, w_init = NA,  max_epochs = 1000, max_clusters = 20, eps = 10^-6)
    {
    
      start_time = Sys.time()
      ## save parameters
      params = list()
      params[["rho"]]         = rho
      params[["alpha"]]       = alpha
      params[["beta"]]        = beta
      params[["max_epochs"]]  = max_epochs
      params[["w_init"]]      = w_init
      
      # check parameter
      if(is.data.frame(input)){(input=as.matrix(input))}
      if (is.numeric(input))
      {
      # normalize data input
      normalized_data <- normalize_data(input)
      } else {stop("Error: Input data is not numeric")}
      
      
      # complement code conversion
      dataset <- complement_coded_conv(normalized_data)
      
      # determine the size of features/variables data
      num_features <- ncol(input)
      
      # init weight
      #w_init = NA
      if(is.na(w_init))
      {
      w <- matrix(rep(1,num_features*2),nrow = 1)
      } else if (dim(w_init)[2]==num_features*2)
      {
        w <- w_init
      } else {stop("Error: Initial weight dimension is not the same as 2*num of features")}
      
      num_clusters <- dim(w)[1]
      
      #init variables
      max_clusters = max_clusters
      num_clusters_old = num_clusters
      cluster_labels = matrix(rep(NA, dim(dataset)[1]))
      iterations = 0
      w_old = w+1
      train_output_fa = list(w = NA, num_clusters = NA, winner = NA)
      index = 1:dim(dataset)[1]
      
      while (((sum(w_old-w)^2)>eps^2) & (iterations < max_epochs)) 
      {
      
        w_old = w
       
        for(i in index)
        {
          train_output_fa <- learn_pattern(dataset[i,], w, rho, alpha, beta, num_clusters, 
                                           max_clusters, output.learn =  train_output_fa)
          
          cluster_labels[i] <- train_output_fa$winner
          dimnames(cluster_labels)[1]<-dimnames(input)[1]
          w <- train_output_fa$w
          num_clusters <- train_output_fa$num_clusters
          
        }
        iterations = iterations+1
        
        if(num_clusters_old != num_clusters)
        {
          w_old = rbind(w_old,replicate(n = num_features*2, rep(1,num_clusters-num_clusters_old)))
          num_clusters_old = num_clusters
        }
      }
        
      fa_clusters = list(matrix(NA,nrow=num_clusters, ncol=num_features))
      size = matrix(NA,num_clusters)
      cent= matrix(NA,nrow=num_clusters,ncol=ncol(input))
      for(k in 1:num_clusters)
      {
        fa_clusters[[k]] <- matrix(input[which(cluster_labels == k),], ncol = num_features)
        dimnames(fa_clusters[[k]])[1]<-dimnames(input[which(cluster_labels == k),])[1]
        dimnames(fa_clusters[[k]])[2]<-dimnames(input)[2]
        if(is.null(nrow(fa_clusters[[k]])))
        {
          size[k] <- 0
        } else {size[k]<-nrow(fa_clusters[[k]])}
      }
      
      
      
      fa_centroids = matrix(NA,nrow=num_clusters,ncol=ncol(input))
      fa_centroids <- recalculate_centroids(fa_centroids,fa_clusters,num_clusters)
      dimnames(fa_centroids)[2]<-dimnames(input)[2]
      
      end_time <- Sys.time()
      running_time = end_time-start_time
      
      FuzzyArt_Out = list()
      FuzzyArt_Out[["labels"]] = cluster_labels
      FuzzyArt_Out[["size"]] = size
      FuzzyArt_Out[["clusters"]] = fa_clusters
      FuzzyArt_Out[["centroids"]] = fa_centroids
      FuzzyArt_Out[["weights"]] = w_old
      FuzzyArt_Out[["params"]] = params
      FuzzyArt_Out[["iterations"]] = iterations
      FuzzyArt_Out[["num_clusters"]] = num_clusters
      FuzzyArt_Out[["running_time"]]= running_time
      return(FuzzyArt_Out)
    }
    
    

    ## Fuzzy ART Testing
    
    fuzzyart_testing <- function(input, FuzzyArt_Out)
    {
      start_time = Sys.time()
      if(is.null(FuzzyArt_Out)) stop("Error. Need to specify FuzzyArt_Out as a FuzzyART model as trained by FuzzyART_train")
      
      # check parameter
      if(is.data.frame(input)){(input=as.matrix(input))}
      if (is.numeric(input))
      {
      # normalize data input
      normalized_data <- normalize_data(input)
      } else {stop("Error: Input data is not numeric")}
      
      
      # complement code conversion
      dataset <- complement_coded_conv(normalized_data)
      num_clusters = FuzzyArt_Out$num_clusters
      
      cluster_labels = matrix(rep(NA, dim(input)[1]))
      cluster_labels = matrix(apply(dataset, MARGIN = 1,FUN = function(dataset){return(category_winner(input = dataset,w = FuzzyArt_Out$w,
                                                                                     alpha = FuzzyArt_Out$params$alpha, 
                                                                                     rho = FuzzyArt_Out$params$rho))}))
      num_clusters = FuzzyArt_Out$num_clusters
      dimnames(cluster_labels)[1]<-dimnames(input)[1]
      
      fa_clusters = list(matrix(NA,nrow=num_clusters, ncol=ncol(input)))
      size = matrix(NA,num_clusters)
      cent= matrix(NA,nrow=num_clusters,ncol=ncol(input))
      for(k in 1:num_clusters)
      {
        fa_clusters[[k]] <- matrix(input[which(cluster_labels == k),], ncol = ncol(input))
        dimnames(fa_clusters[[k]])[1]<-dimnames(input[which(cluster_labels == k),])[1]
        dimnames(fa_clusters[[k]])[2]<-dimnames(input)[2]
        if(is.null(nrow(fa_clusters[[k]])))
        {
          size[k] <- 0
        } else {size[k]<-nrow(fa_clusters[[k]])}
      }
      
      fa_centroids = matrix(NA,nrow=num_clusters,ncol=ncol(input))
      fa_centroids <- recalculate_centroids(fa_centroids,fa_clusters,num_clusters)
      dimnames(fa_centroids)[2]<-dimnames(input)[2]
      
      end_time <- Sys.time()
      running_time = end_time-start_time
      
      FuzzyArt_Res = list()
      FuzzyArt_Res[["labels"]] = cluster_labels
      FuzzyArt_Res[["size"]] = size
      FuzzyArt_Res[["clusters"]] = fa_clusters
      FuzzyArt_Res[["centroids"]] = fa_centroids
      FuzzyArt_Res[["weights"]] = FuzzyArt_Out$w
      FuzzyArt_Res[["params"]] = FuzzyArt_Out$params
      FuzzyArt_Res[["num_clusters"]] = num_clusters
      FuzzyArt_Res[["running_time"]]= running_time
      return(FuzzyArt_Res)
    }
  
    ## K-Means Clustering
    kmeans_train <- function(input, k, centroids = NULL, max_iter = 1000)
    {
      start_time = Sys.time()
      iterations = 0
      clust= list(matrix(NA,nrow=k, ncol=dim(input)[2]))
      labels=matrix(rep(NA, dim(input)[1]))
      size = matrix(NA,k)
      if(is.data.frame(input)){(input=as.matrix(input))}
      
      if(is.null(centroids))
      {
      centroids = matrix(NA,nrow=k,ncol=ncol(input))
        for (i in 1:k) {
          rand <- round(runif(1,1,nrow(input)),0)
          centroids[i,] =  rbind(input[rand,])
        } 
      } else {centroids=centroids}
      
      while(iterations <= max_iter)
      {
        centroids_old = centroids
        labels = assigning_cluster(input, centroids, k)
        for(i in 1:k)
        {
          clust[[i]] <- input[which(labels == i),]
          dimnames(clust[[i]])[1]<-dimnames(input[which(labels == i),])[1]
          dimnames(clust[[i]])[2]<-dimnames(input)[2]
          if(is.null(nrow(clust[[i]])))
          {
            size[i] <- 0
          } else {size[i]<-nrow(clust[[i]])}
        }
        centroids = recalculate_centroids(centroids_old, clust, k)
        if(all(centroids_old == centroids, na.rm = T)==TRUE)
        {
          break
        } else
        {
          iterations = iterations+1
        }
      }
      dimnames(labels)[1]<-dimnames(input)[1]
     
      
      end_time = Sys.time()
      running_time = end_time-start_time
      Kmeans_Res = list()
      Kmeans_Res$labels = labels
      Kmeans_Res$size = size
      Kmeans_Res$clusters = clust
      Kmeans_Res$centroids = centroids
      Kmeans_Res$running_time = running_time
      return(Kmeans_Res)
    }
    
    ## FAKMCT
    
    
    train_output_fa = list(w = NA, num_clusters = NA, winner = NA)
    FuzzyArt_Out = list(NA)
    FuzzyArt_Out <- fuzzyart_training(input, rho, alpha, beta, w_init, max_epochs, max_clusters)
    FuzzyArt_Res = list(NA)
    FuzzyArt_Res <- fuzzyart_testing(input,FuzzyArt_Out)
    Kmeans_Res = list (NA)
    Kmeans_Res <- kmeans_train(input, k = FuzzyArt_Res$num_clusters, centroids = FuzzyArt_Res$centroids)

    end_time <- Sys.time()
    running_time = end_time - start_time
    
    
    
    fakmct_res = list()
    fakmct_res[["labels"]]=Kmeans_Res$labels
    fakmct_res[["size"]]=Kmeans_Res$size
    fakmct_res[["clusters"]]=Kmeans_Res$clusters
    fakmct_res[["centroids"]]=Kmeans_Res$centroids
    fakmct_res[["weights"]]= FuzzyArt_Res$w
    fakmct_res[["params"]] = params
    fakmct_res[["num_clusters"]] = FuzzyArt_Res$num_clusters
    fakmct_res[["running_time"]]= running_time
    fakmct_res[["FuzzyArt_Out"]]=FuzzyArt_Out
    fakmct_res[["FuzzyArt_Res"]]=FuzzyArt_Res
    fakmct_res[["Kmeans_Res"]]=Kmeans_Res
    return(fakmct_res)
    
}
```

```{r}
modiris<-ffakmct(inputs, alpha = 0.3, rho = 0.5, beta = 0.08, max_epochs = 50, max_clusters = 5)
modiris
```


```{r}
kenapa <- fuzzyart_training(book3, alpha = 0.3, rho = 0.5, beta = 0.08, max_epochs = 1000, max_clusters = 5)
kenapa
```
```{r}
AKHIRNYA2 <- fuzzyart_training(data100, alpha = 0.01, rho = 0.9, beta = 1, max_epochs = 1000)
AKHIRNYA2
```

```{r}
masasih<-kmeans_train(data100,k=AKHIRNYA$num_clusters,centroids = AKHIRNYA$FuzzyArt_Res$centroids)
```

```{r}
AKHIRNYA <- ffakmct(data100, alpha = 0.01, rho = 0.90, beta = 1, max_epochs = 1000)
AKHIRNYA$FuzzyArt_Res$centroids 
```

```{r}
library(FuzzyART)
misalnih <- FuzzyART_train(data100,rho=0.7,alpha = 0.000001, beta = 1, max_epochs=1000)
fa40r5 <- fuzzyart_training(data100,rho = 0.70, alpha = 0.000001, beta = 1)
```
```{r}
misalnih
fa40r5

```
```{r}
plot(book3)
```

```{r}
dv<-dist(data100)
dv
library(seriation)
pv<-VAT(dv)
```

```{r}

```

